{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4c3d335-5962-45e7-9ce0-f3f28c916de2",
   "metadata": {},
   "source": [
    "VMLS - Study Guide Chapter 4 Name:Joaquin Quintana\n",
    "\n",
    " Submit your work in Gradescope as a PDF.\n",
    "\n",
    " Identify the question number as you submit.\n",
    "\n",
    " One section per page (if a page or less)\n",
    "\n",
    " Do not start a new question in the middle of a page.\n",
    " \n",
    "\n",
    "2.(20 pts) Select one page or section of Chapter One of VMLS to annotate. Include a\n",
    "screenshot of your annotation here. (not example 4.4.1 since that is the next question)\n",
    "\n",
    "4.(20 pts) Explain the solution to 4.1 here in your own words. (Since you are given a\n",
    "solution, you will be graded on your ability to explain).\n",
    "\n",
    "5.(20 pts) Explain the solution to 4.2 here in your own words. (Since you are given a\n",
    "solution, you will be graded on your ability to explain).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79be39ad-421c-42c2-ac8d-4249958b37ad",
   "metadata": {},
   "source": [
    "**1.(20pts) Describe the K-Means algorithm in your own words to someone who has never heard of it. Explain each step.**\n",
    "\n",
    "K-means is an algorithm which can take in a set of data and partition the data into k-groups based off like characteristics. K is the number of groups to partition the data into (k is also the number of centroids) and is determined experimentally. \n",
    "\n",
    "**Pseudo code**\n",
    "\n",
    "1. To intialize the problem let's randomly choose k data points in our data set to be our k-centroids. \n",
    "2. Assign each data point to the centroid which is closest\n",
    "3. Compute the average for each group and update each group's centroid to be its average. These new centroids are used in the next iteration of k-means. \n",
    "4. Repeat steps 2 and 3 for each group up until all centroids are no longer capable of being updated and it has converged. At this point we have our k clusters. \n",
    "\n",
    "Step 2 and 3 above are the iterative portion of the algorithm. This is, it jumps between choosing group representatives (centroids) and choosing group assignments. Truly we are computing the mean of the squared distance from the data vectors to their closest representative and this is called $J^{clust}$. The goal is to minimize $J^{clust}$ and this can be done by minimizing the contribution of each k-group. Conveniently, $J^{clust}$ can be rearragned so it equals the sum of each groups contribution $J_j$ or $J^{clust} = J_1 +...J_k$. \n",
    "\n",
    "With each $J_j = \\frac{1}{N} \\sum_{i \\epsilon G_j}||x_i-z_j||^2$\n",
    "\n",
    "Here $x_i$ is the vectors in the group $j$ and $G_j$ is the number of elements in group $j$. Therefore, we are truly trying to find each $z_j$ which minimizes it's $J_j$ term the most. The simple solution here is to use the centroid aka the mean of the vectors $x_i$ in it's group. This implies $z_j = \\frac{1}{|G_j|} \\sum_{i \\epsilon G_j}x_i$ which is the mean of group $j$. So overall, k-means iteratively runs until each $z_j$ is found and produces the smallest $J^{clust}$ possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d283d77-6e36-49ac-8981-d3ceb48e5ad8",
   "metadata": {},
   "source": [
    "**3.(20 pts) Explain example 4.4.1 in detail. Why is this an interesting example? What is K in this example?**\n",
    "\n",
    "4.4.1 looks at the classic machine learning data set known as MNIST (Mixed National Institute of Standards). This data set is 60000 images of hand written digits each being represented as a vector of size 784 or as an image array 28*28. The problem discussed uses k-mean clustering to cluster the images into k=20 groups. In this example the k-means algorithm was run 20 times with random assignment of the vectors to k groups. What we see is that k-means does a good job of clustering the 10 hand written digits into 20 different cluster with some understandable confusion. From the clustering objective plots it is clear that the algorithm performs slightly differently on each run and that $J^{clust}$ is becomes more or less constant after a few iterations.\n",
    "\n",
    "I think that people find this to be an interesting example because it is somewhat abstract. The computer is taking in an image in vector form with only gray scale intensity values and it is capable of grouping numbers of the same digit with one another. It does almost make it feel like the computer or algorithm has figured out the problem, but in reality it is simply following the k-means algorithm and computing the mean of the squared distance from the data vectors to their closest representative until it has converged and $J^{clust}$ is minimized. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b6482d-87f6-46f0-8fb5-909446ebad7b",
   "metadata": {},
   "source": [
    "4.\n",
    "\n",
    "**4a**\n",
    "\n",
    "Given: $J(z) = \\sum_i^L||x_i-\\bar x - (z-\\bar x)||^2 = J(z) = \\sum_i^L(||x_i-\\bar x||^2 -2(x_i-\\bar x)^T(z-\\bar x)) + L |z-\\bar x|$\n",
    "\n",
    "**Let $a = x_i - \\bar x$ and $b= z-\\bar x$**\n",
    "\n",
    "Binomial expansion of the norm(a-b) for vectors a and b:  $||a-b||^2 = ||a||^2 - 2a^Tb + ||b||^2$\n",
    "\n",
    "Since $b= z-\\bar x$ is not dependent on i but L we can factor it out of the sum. This is also the sum of the norm(a-b) so... \n",
    "\n",
    "$\\sum_i^L(||a||^2 - 2a^Tb) + L||b||^2 = $\n",
    "\n",
    "Substitute a and b into the equation \n",
    "\n",
    "$= \\sum_i^L( ||x_i - \\bar x||^2 - 2(x_i - \\bar x)^T( z-\\bar x) ) + L|| z-\\bar x||^2  $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3dfd02-9d59-4794-8efb-2775a9a94c9b",
   "metadata": {},
   "source": [
    "**4b**\n",
    "\n",
    "Again since **Let $a = x_i - \\bar x$, $b= z-\\bar x$ and since be is not dependent on i we can remove it from the sum**\n",
    "\n",
    "$ \\sum_1^L(x_i-\\bar x)^T(z-\\bar x) = 0 $\n",
    "\n",
    "Equation above rewriten and the goal is to prove the left side equals 0: \n",
    "\n",
    "$\\bigg (\\sum_1^L(x_i-\\bar x) \\bigg )^T(z-\\bar x)$\n",
    "\n",
    "Note $\\bar x = \\frac{x_1 + ... + x_n}{L}$\n",
    "\n",
    "Substitute $\\bar x$\n",
    "\n",
    "$\\bigg (\\sum_1^L \\big(x_i-(\\frac{x_1 + ... + x_n}{L} )\\big) \\bigg )^T(z-\\bar x)$\n",
    "\n",
    "From here we see all we need to prove $\\sum_1^L(x_i-\\bar x) = 0$. So lets pull L out from the sum since $\\frac{1}{L}$ is a constant and doesn't depend on i.  \n",
    "\n",
    "$\\bigg (\\sum_1^L \\big(x_i-({x_1 + ... + x_n})\\big) \\bigg )^T(z-\\bar x)$\n",
    "\n",
    "\n",
    "$= \\bigg (\\sum_1^L \\big(x_i-x_i\\big) \\bigg )^T(z-\\bar x)$ \n",
    "\n",
    "\n",
    "Since $x_i -x_i = 0$, we know $\\bigg (\\sum_1^L(x_i-\\bar x) \\bigg )^T(z-\\bar x) = 0$ and since we see the inner product is 0 we know this function is linear. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679ba888-6dc9-4e3d-9845-d3f117f33ea2",
   "metadata": {},
   "source": [
    "**4c**\n",
    "\n",
    "From a we are given $J(z)= \\sum_i^L( ||x_i - \\bar x||^2 - 2(x_i - \\bar x)^T( z-\\bar x) ) + L|| z-\\bar x||^2 $ and in be we discover the dot product equals zeros as this is a linear function. This gives us ... $J(z)= \\sum_i^L( ||x_i - \\bar x||^2 + L|| z-\\bar x||^2 $. \n",
    "\n",
    "So when $z = \\bar x$ we get \n",
    "\n",
    "$J(z)=J( \\bar x) = \\sum_i^L ||x_i - z||^2 + L|| z-z||^2 $\n",
    "\n",
    "$J(z)= J( \\bar x)= \\sum_i^L||x_i - z||^2 $\n",
    "\n",
    "Any other time we get ... \n",
    "\n",
    "$J(z)= \\sum_i^L ||x_i - \\bar x||^2 + L|| z-\\bar x||^2 $\n",
    "\n",
    "We see that if $z = \\bar x$ then it will always be smaller than the function when $J(\\bar )$ will always be less than $J(z)$ if $z != \\bar x$. This is, $J(z) > J(\\bar x)$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1399b7fe-c962-404b-8db8-c6775ddca1e9",
   "metadata": {},
   "source": [
    "5.\n",
    "\n",
    "**5a** This is a simple one. Each group representive is computed using the formula $z_j = \\frac{1}{|G_j|} \\sum_{i \\epsilon G_j}x_i$, where $x_i$ is the vectors in the group $j$ and $|G_j|$ is the number of elements in group $j$. Since all the elements in $x_i$ are nonnegative we expect the average of them to also be nonnegative. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2261ff54-528f-49d3-8c0d-c63c8f361d59",
   "metadata": {},
   "source": [
    "**5b**\n",
    "\n",
    "Looking at this equation again  $z_j = \\frac{1}{|G_j|} \\sum_{i \\epsilon G_j}x_i$ we know the representatives is the average of the group $j$. Since each vector sums to one we know that by taking the average of that same vector we would get one and therefore we see the representative must also sum to 1. \n",
    "\n",
    "Show this by multiplying both sides of the function by $1^T$\n",
    "\n",
    "\n",
    "$1^Tz_j = 1^T\\big( \\frac{1}{|G_j|} \\sum_{i \\epsilon G_j}x_i \\big)$\n",
    "\n",
    "$ =  \\frac{1}{|G_j|} \\sum_{i \\epsilon G_j}1^Tx_i$\n",
    "\n",
    "Since $\\sum_{i \\epsilon G_j}1^Tx_i = 1$ and by way of substitution\n",
    "\n",
    "$ =  \\frac{1}{|G_j|} \\sum_{i \\epsilon G_j}1 = \\frac{|G_j|}{|G_j|} = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c5e145-5214-478a-9463-ba0a0d3982df",
   "metadata": {},
   "source": [
    "**5c**\n",
    "\n",
    "Since we are dealing with boolean values there can only be three results. We can have two groups which are completely composed of ones, zeros or a combintation of the two. For the first and second options we would expect to have representives which equal zero and one. For group which has a combination of zeros and ones we have a representive which equals the number of values in the group which equal one divide by the size of the group. This last representive would therefore be a fraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb7438-cc7f-4e0b-a7f2-c528185d7f13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
